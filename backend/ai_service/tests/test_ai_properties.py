"""
Property-based tests for AI disease prediction logic.

Feature: cattle-health-system
Validates: Requirements 3.2, 3.3, 3.4, 3.5
"""
import pytest
from hypothesis import given, strategies as st, settings, assume
from hypothesis.extra.django import TestCase
from django.contrib.auth import get_user_model
from rest_framework.test import APIClient
from rest_framework_simplejwt.tokens import RefreshToken
import bcrypt
from io import BytesIO
from PIL import Image
import base64

from cattle.models import Cattle
from health.models import SymptomEntry
from ai_service.client import ai_client, AIServiceException

User = get_user_model()


# Custom strategies for generating test data
@st.composite
def user_with_cattle(draw):
    """Generate a user with a cattle profile."""
    email = draw(st.text(
        alphabet=st.characters(whitelist_categories=('Ll', 'Nd')),
        min_size=5,
        max_size=15
    )) + "@test.com"
    
    return {
        'email': email,
        'phone': f"+1{draw(st.integers(min_value=1000000000, max_value=9999999999))}",
        'name': draw(st.text(min_size=3, max_size=30, alphabet=st.characters(whitelist_categories=('Ll', 'Lu', 'Zs')))),
        'password': 'TestPass123',
        'role': 'owner',
        'cattle': {
            'breed': draw(st.text(min_size=2, max_size=50, alphabet=st.characters(whitelist_categories=('Ll', 'Lu', 'Zs')))),
            'age': draw(st.integers(min_value=0, max_value=25)),
            'identification_number': draw(st.text(min_size=5, max_size=20, alphabet=st.characters(whitelist_categories=('Lu', 'Nd')))),
            'gender': draw(st.sampled_from(['male', 'female'])),
            'weight': draw(st.one_of(
                st.none(),
                st.decimals(min_value=50, max_value=1500, places=2, allow_nan=False, allow_infinity=False)
            )),
        }
    }


@st.composite
def valid_symptoms(draw):
    """Generate valid symptom descriptions."""
    # Base symptoms
    base_symptoms = [
        "high fever and loss of appetite",
        "coughing and difficulty breathing",
        "swollen udder with discharge",
        "limping and lameness in left leg",
        "diarrhea and dehydration",
        "blisters around mouth and hooves",
        "runny nose and eye discharge",
        "lethargy and weakness"
    ]
    
    # Additional descriptors
    descriptors = [
        "severe", "mild", "moderate", "acute", "chronic",
        "sudden onset", "gradual development", "persistent",
        "intermittent", "worsening", "improving"
    ]
    
    # Duration indicators
    durations = [
        "for 2 days", "since yesterday", "for a week",
        "over the past few days", "recently noticed"
    ]
    
    base = draw(st.sampled_from(base_symptoms))
    descriptor = draw(st.sampled_from(descriptors))
    duration = draw(st.sampled_from(durations))
    
    # Combine into a realistic symptom description
    symptom_text = f"The cow has {descriptor} {base} {duration}."
    
    # Ensure minimum length
    assume(len(symptom_text) >= 10)
    
    return symptom_text


def create_test_image():
    """Create a test image for upload."""
    img = Image.new('RGB', (200, 200), color='red')
    img_io = BytesIO()
    img.save(img_io, format='JPEG')
    img_io.seek(0)
    return img_io


@pytest.mark.django_db
class TestPredictionStructureCompleteness(TestCase):
    """
    Property 9: Prediction structure completeness
    For any disease prediction generated by the AI engine, the result should include 
    disease name, confidence score (0-100), and severity level.
    
    Feature: cattle-health-system, Property 9: Prediction structure completeness
    Validates: Requirements 3.2
    """
    
    @given(data=user_with_cattle(), symptoms=valid_symptoms())
    @settings(max_examples=50, deadline=None)
    def test_prediction_structure_completeness(self, data, symptoms):
        """Test that all predictions have required structure."""
        # Create user and cattle
        hashed_password = bcrypt.hashpw(data['password'].encode('utf-8'), bcrypt.gensalt())
        user = User.objects.create(
            email=data['email'],
            phone=data['phone'],
            name=data['name'],
            role=data['role'],
            password=hashed_password.decode('utf-8')
        )
        
        cattle = Cattle.objects.create(
            owner=user,
            **data['cattle']
        )
        
        # Make prediction request
        client = APIClient()
        refresh = RefreshToken.for_user(user)
        client.credentials(HTTP_AUTHORIZATION=f'Bearer {str(refresh.access_token)}')
        
        prediction_data = {
            'cattle_id': str(cattle.id),
            'symptoms': symptoms,
            'save_assessment': False  # Don't save for property tests
        }
        
        response = client.post('/api/ai/predict/', json=prediction_data, format='json')
        
        # Should return successful response
        assert response.status_code in [200, 503], f"Expected 200 or 503, got {response.status_code}"
        
        result = response.json()
        
        if response.status_code == 200 and result.get('success'):
            predictions = result.get('predictions', [])
            
            # Each prediction should have required structure
            for prediction in predictions:
                # Required fields
                assert 'diseaseName' in prediction, "Prediction missing disease name"
                assert 'confidenceScore' in prediction, "Prediction missing confidence score"
                assert 'severityLevel' in prediction, "Prediction missing severity level"
                
                # Validate field types and ranges
                assert isinstance(prediction['diseaseName'], str), "Disease name should be string"
                assert len(prediction['diseaseName']) > 0, "Disease name should not be empty"
                
                assert isinstance(prediction['confidenceScore'], (int, float)), "Confidence score should be numeric"
                assert 0 <= prediction['confidenceScore'] <= 100, "Confidence score should be 0-100"
                
                assert isinstance(prediction['severityLevel'], str), "Severity level should be string"
                assert prediction['severityLevel'] in ['low', 'medium', 'high', 'critical', 'very_low'], \
                    f"Invalid severity level: {prediction['severityLevel']}"


@pytest.mark.django_db
class TestPredictionRankingByConfidence(TestCase):
    """
    Property 10: Prediction ranking by confidence
    For any set of multiple disease predictions, they should be ordered by 
    confidence score in descending order.
    
    Feature: cattle-health-system, Property 10: Prediction ranking by confidence
    Validates: Requirements 3.3
    """
    
    @given(data=user_with_cattle(), symptoms=valid_symptoms())
    @settings(max_examples=50, deadline=None)
    def test_predictions_ranked_by_confidence(self, data, symptoms):
        """Test that predictions are ranked by confidence score."""
        # Create user and cattle
        hashed_password = bcrypt.hashpw(data['password'].encode('utf-8'), bcrypt.gensalt())
        user = User.objects.create(
            email=data['email'],
            phone=data['phone'],
            name=data['name'],
            role=data['role'],
            password=hashed_password.decode('utf-8')
        )
        
        cattle = Cattle.objects.create(
            owner=user,
            **data['cattle']
        )
        
        # Make prediction request
        client = APIClient()
        refresh = RefreshToken.for_user(user)
        client.credentials(HTTP_AUTHORIZATION=f'Bearer {str(refresh.access_token)}')
        
        prediction_data = {
            'cattle_id': str(cattle.id),
            'symptoms': symptoms,
            'save_assessment': False
        }
        
        response = client.post('/api/ai/predict/', json=prediction_data, format='json')
        
        if response.status_code == 200:
            result = response.json()
            
            if result.get('success'):
                predictions = result.get('predictions', [])
                
                # If multiple predictions, check ordering
                if len(predictions) > 1:
                    confidence_scores = [pred['confidenceScore'] for pred in predictions]
                    
                    # Verify descending order
                    for i in range(len(confidence_scores) - 1):
                        assert confidence_scores[i] >= confidence_scores[i + 1], \
                            f"Predictions not in descending order: {confidence_scores}"


@pytest.mark.django_db
class TestLowConfidenceRecommendation(TestCase):
    """
    Property 11: Low confidence veterinarian recommendation
    For any prediction with confidence score below 40%, the response should include 
    a recommendation to consult a veterinarian.
    
    Feature: cattle-health-system, Property 11: Low confidence veterinarian recommendation
    Validates: Requirements 3.4
    """
    
    @given(data=user_with_cattle())
    @settings(max_examples=50, deadline=None)
    def test_low_confidence_vet_recommendation(self, data):
        """Test that low confidence predictions include vet recommendation."""
        # Create user and cattle
        hashed_password = bcrypt.hashpw(data['password'].encode('utf-8'), bcrypt.gensalt())
        user = User.objects.create(
            email=data['email'],
            phone=data['phone'],
            name=data['name'],
            role=data['role'],
            password=hashed_password.decode('utf-8')
        )
        
        cattle = Cattle.objects.create(
            owner=user,
            **data['cattle']
        )
        
        # Use vague symptoms to likely get low confidence
        vague_symptoms = "The cow seems unwell and not eating much."
        
        client = APIClient()
        refresh = RefreshToken.for_user(user)
        client.credentials(HTTP_AUTHORIZATION=f'Bearer {str(refresh.access_token)}')
        
        prediction_data = {
            'cattle_id': str(cattle.id),
            'symptoms': vague_symptoms,
            'save_assessment': False
        }
        
        response = client.post('/api/ai/predict/', json=prediction_data, format='json')
        
        if response.status_code == 200:
            result = response.json()
            
            if result.get('success'):
                predictions = result.get('predictions', [])
                
                for prediction in predictions:
                    confidence = prediction.get('confidenceScore', 100)
                    
                    if confidence < 40:
                        # Should have veterinarian recommendation
                        recommendation = prediction.get('recommendation', '')
                        assert 'veterinarian' in recommendation.lower() or 'vet' in recommendation.lower(), \
                            f"Low confidence prediction ({confidence}%) missing vet recommendation"


@pytest.mark.django_db
class TestAIErrorHandlingClarity(TestCase):
    """
    Property 12: AI error handling clarity
    For any input that the AI engine cannot process, the error message should include 
    specific corrective actions.
    
    Feature: cattle-health-system, Property 12: AI error handling clarity
    Validates: Requirements 3.5
    """
    
    @given(data=user_with_cattle())
    @settings(max_examples=30, deadline=None)
    def test_error_messages_include_corrective_actions(self, data):
        """Test that error messages provide specific corrective actions."""
        # Create user and cattle
        hashed_password = bcrypt.hashpw(data['password'].encode('utf-8'), bcrypt.gensalt())
        user = User.objects.create(
            email=data['email'],
            phone=data['phone'],
            name=data['name'],
            role=data['role'],
            password=hashed_password.decode('utf-8')
        )
        
        cattle = Cattle.objects.create(
            owner=user,
            **data['cattle']
        )
        
        client = APIClient()
        refresh = RefreshToken.for_user(user)
        client.credentials(HTTP_AUTHORIZATION=f'Bearer {str(refresh.access_token)}')
        
        # Test various error conditions
        error_test_cases = [
            {
                'data': {
                    'cattle_id': str(cattle.id),
                    'symptoms': 'x',  # Too short
                    'save_assessment': False
                },
                'expected_error_type': 'validation'
            },
            {
                'data': {
                    'cattle_id': str(cattle.id),
                    'symptoms': '',  # Empty
                    'save_assessment': False
                },
                'expected_error_type': 'validation'
            },
            {
                'data': {
                    'cattle_id': '00000000-0000-0000-0000-000000000000',  # Invalid cattle
                    'symptoms': 'Valid symptom description here',
                    'save_assessment': False
                },
                'expected_error_type': 'not_found'
            }
        ]
        
        for test_case in error_test_cases:
            response = client.post('/api/ai/predict/', json=test_case['data'], format='json')
            
            # Should return error status
            assert response.status_code >= 400, f"Expected error status, got {response.status_code}"
            
            # Check error message content
            if response.status_code == 400:  # Validation errors
                error_data = response.json()
                
                # Should contain specific field errors or corrective guidance
                has_specific_error = (
                    'symptoms' in error_data or 
                    'cattle_id' in error_data or
                    'error' in error_data or
                    'message' in error_data
                )
                
                assert has_specific_error, "Error response should contain specific error information"
    
    @given(data=user_with_cattle())
    @settings(max_examples=20, deadline=None)
    def test_ai_service_unavailable_error_clarity(self, data):
        """Test error clarity when AI service is unavailable."""
        # Create user and cattle
        hashed_password = bcrypt.hashpw(data['password'].encode('utf-8'), bcrypt.gensalt())
        user = User.objects.create(
            email=data['email'],
            phone=data['phone'],
            name=data['name'],
            role=data['role'],
            password=hashed_password.decode('utf-8')
        )
        
        cattle = Cattle.objects.create(
            owner=user,
            **data['cattle']
        )
        
        client = APIClient()
        refresh = RefreshToken.for_user(user)
        client.credentials(HTTP_AUTHORIZATION=f'Bearer {str(refresh.access_token)}')
        
        prediction_data = {
            'cattle_id': str(cattle.id),
            'symptoms': 'The cow has fever and is not eating well.',
            'save_assessment': False
        }
        
        response = client.post('/api/ai/predict/', json=prediction_data, format='json')
        
        # If AI service is unavailable (503), check error message clarity
        if response.status_code == 503:
            result = response.json()
            
            # Should have clear error message
            assert 'error' in result or 'message' in result, "Service unavailable error should have clear message"
            
            # Should mention alternative actions
            error_text = str(result).lower()
            has_alternative_action = (
                'try again' in error_text or
                'later' in error_text or
                'veterinarian' in error_text or
                'consult' in error_text
            )
            
            assert has_alternative_action, "Service unavailable error should suggest alternative actions"


@pytest.mark.django_db
class TestPredictionConsistency(TestCase):
    """
    Additional property test for prediction consistency.
    Ensures that similar symptoms produce consistent predictions.
    """
    
    @given(data=user_with_cattle())
    @settings(max_examples=20, deadline=None)
    def test_similar_symptoms_consistent_predictions(self, data):
        """Test that similar symptom descriptions produce consistent top predictions."""
        # Create user and cattle
        hashed_password = bcrypt.hashpw(data['password'].encode('utf-8'), bcrypt.gensalt())
        user = User.objects.create(
            email=data['email'],
            phone=data['phone'],
            name=data['name'],
            role=data['role'],
            password=hashed_password.decode('utf-8')
        )
        
        cattle = Cattle.objects.create(
            owner=user,
            **data['cattle']
        )
        
        client = APIClient()
        refresh = RefreshToken.for_user(user)
        client.credentials(HTTP_AUTHORIZATION=f'Bearer {str(refresh.access_token)}')
        
        # Test with similar symptom descriptions
        similar_symptoms = [
            "The cow has high fever and loss of appetite for 2 days.",
            "High temperature and not eating for the past 2 days.",
            "Fever and refusing food since 2 days ago."
        ]
        
        predictions_list = []
        
        for symptoms in similar_symptoms:
            prediction_data = {
                'cattle_id': str(cattle.id),
                'symptoms': symptoms,
                'save_assessment': False
            }
            
            response = client.post('/api/ai/predict/', json=prediction_data, format='json')
            
            if response.status_code == 200:
                result = response.json()
                if result.get('success'):
                    predictions = result.get('predictions', [])
                    if predictions:
                        predictions_list.append(predictions[0]['diseaseName'])
        
        # If we got multiple predictions, check for consistency
        if len(predictions_list) >= 2:
            # At least 50% should be the same top prediction for similar symptoms
            most_common = max(set(predictions_list), key=predictions_list.count)
            consistency_ratio = predictions_list.count(most_common) / len(predictions_list)
            
            # Allow some variation but expect reasonable consistency
            assert consistency_ratio >= 0.5, \
                f"Similar symptoms should produce consistent predictions. Got: {predictions_list}"